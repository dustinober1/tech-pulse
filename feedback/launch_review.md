Launch readiness review (Tech-Pulse)

- Critical – Semantic search integration is non-functional: `data_loader.setup_vector_db` calls `vector_search.initialize/clear_collection/get_collection_info` and passes full doc dicts to `add_documents` (data_loader.py:202-243), but `VectorSearchManager` has none of those methods and expects `add_documents(documents, ids, ...)`. Likewise `semantic_search` formats the result as if `search` returned a list with `similarity` values, but `VectorSearchManager.search` returns a dict with distances only. The Initialize Search / Smart Search tab currently raises AttributeError/TypeError and cannot operate. Align the APIs (or adjust callers) so initialization and search produce similarity-scored results that respect thresholds.
- Critical – Real-time mode blocks the Streamlit app: `render_news_analysis_tab` wraps the page in `while True` with `time.sleep` (app.py:1068-1091). Streamlit scripts must finish per run; this loop never returns and will hang sessions/threads, preventing other users or tabs from rendering. Replace with `st_autorefresh` or a timer-driven `st.rerun` pattern instead of an infinite loop.
- Critical – Predictive tabs crash immediately: `_get_available_technologies` references `self.data_loader` (src/phase7/predictive_analytics/dashboard.py:266-274), but no such attribute is created (comment notes it was removed). Tabs 3-5 trigger AttributeError before rendering. Instantiate the needed data access object or gate these tabs until data is available.
- High – Multi-source fetch typo: `fetch_all_sources` passes `rass_categories` to `_fetch_rss_content` (src/phase7/source_connectors/aggregator.py:109). The NameError aborts multi-source aggregation and `fetch_multi_source_data` logs an error, so Reddit/RSS/Twitter never populate. Fix the parameter name and add a regression test.
- Medium – Config duplication: `dashboard_config.py` defines `ERROR_MESSAGES` and `SUCCESS_MESSAGES` twice; the second set silently overwrites the first, dropping entries like PDF and semantic search text. Consolidate into a single dict to avoid confusing messaging and missed copy changes.
- Medium – Startup/network resilience: Hacker News requests have no timeouts/backoff, and NLTK downloads the VADER lexicon at import time. In production or Streamlit Cloud this can hang startup or fail without outbound network. Add reasonable timeouts/retries and vendor the lexicon (or fail gracefully) to keep the app responsive.
